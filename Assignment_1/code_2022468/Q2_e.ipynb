{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M7C7ZE0YsKBG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, roc_auc_score, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu_GQwAexINR",
        "outputId": "50efc0ef-dc4f-400c-e883-c12c72bb5b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 4238\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/HeartDisease.csv\")\n",
        "\n",
        "# Fill missing values....... fill with mean median mode depending on data type\n",
        "\n",
        "numerical_cols = ['age','education','cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']\n",
        "categorical_cols = ['male','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','HeartDisease']\n",
        "# For numerical columns\n",
        "# numerical_cols = ['totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'cigsPerDay', 'age']\n",
        "data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
        "\n",
        "# For categorical columns\n",
        "# categorical_cols = ['male', 'education', 'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes']\n",
        "data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])\n",
        "\n",
        "train_data = data\n",
        "\n",
        "# Separate features and target variable if you have one (uncomment and adjust if needed)\n",
        "X_train = train_data.drop('HeartDisease', axis=1)\n",
        "Y_train = train_data['HeartDisease']\n",
        "\n",
        "\n",
        "# Check the sizes\n",
        "print(f\"Training set size: {X_train.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iEL_7C-c0fBX"
      },
      "outputs": [],
      "source": [
        "#converting the pandas dataframe to numpy array\n",
        "\n",
        "X_train = X_train.values\n",
        "Y_train = Y_train.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Om03k-RdfcbP"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XeZAZixKfdGZ"
      },
      "outputs": [],
      "source": [
        "def accuracy(predictions, groundTruth):\n",
        "  return np.mean(predictions == groundTruth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xEseNDJG8Ghr"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression():\n",
        "\n",
        "    def __init__(self, learningRate, epochs, classThresh = 0.5):\n",
        "        self.learningRate = learningRate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.classThresh = classThresh\n",
        "\n",
        "        self.costList = None\n",
        "        self.accuracyList = None\n",
        "\n",
        "    def getLoss(self):\n",
        "      return self.costList\n",
        "\n",
        "    def getAccuracy(self):\n",
        "      return self.accuracyList\n",
        "\n",
        "    def gradientDescent(self, X, Y):\n",
        "        m, n = X.shape\n",
        "        self.weights = np.ones(n) #initialising the weights as 0s\n",
        "        self.bias = 1 #initialising the bias as zero\n",
        "\n",
        "        self.costList = []\n",
        "        self.accuracyList = []\n",
        "\n",
        "        epsilon = 1e-10  # Small constant to prevent log(0)\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "\n",
        "            hypothesis = np.dot(X, self.weights) + self.bias\n",
        "            Y_prediction = sigmoid(hypothesis)\n",
        "\n",
        "            # Cost Function J(w, b), cross entropy loss\n",
        "            cost = -(1/m) * np.sum(Y * np.log(Y_prediction + epsilon) + (1 - Y) * np.log(1 - Y_prediction + epsilon))\n",
        "\n",
        "            #Accuracy\n",
        "            classification = [0 if y<= self.classThresh else 1 for y in Y_prediction]\n",
        "            acc = accuracy(classification, Y)\n",
        "\n",
        "            self.costList.append(cost)\n",
        "            self.accuracyList.append(acc)\n",
        "\n",
        "            #calculating the gradients (partial derivative of the cost function J(w, b) wrt weights and bias)\n",
        "            dw = (1/m) * np.dot(X.T, (Y_prediction - Y))\n",
        "            db = (1/m) * np.sum(Y_prediction - Y)\n",
        "\n",
        "            self.weights = self.weights - self.learningRate * dw\n",
        "            self.bias = self.bias - self.learningRate * db\n",
        "\n",
        "            # if _ % (self.epochs // 10) == 0:  # Print cost every 10% of iterations\n",
        "            #     print(f\"Cost after {_} iterations: {cost} & accuracy : {acc}\")\n",
        "\n",
        "\n",
        "    def classify(self, X):\n",
        "        m, n = X.shape\n",
        "\n",
        "        hypothesis = np.dot(X, self.weights) + self.bias\n",
        "        Y_prediction = sigmoid(hypothesis)\n",
        "\n",
        "        classLabels = [0 if y <= self.classThresh else 1 for y in Y_prediction]\n",
        "\n",
        "        return classLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NAjPYmKVx-fF"
      },
      "outputs": [],
      "source": [
        "def fit_min_max_scaling(X):\n",
        "    return (X - X.min()) / (X.max() - X.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "td17C3RQFDFq"
      },
      "outputs": [],
      "source": [
        "# spliting the dataset into k folds\n",
        "def createKFolds(X, Y, k):\n",
        "    # Shuffle data\n",
        "    indices = np.arange(X.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "\n",
        "    X_shuffled = X[indices]\n",
        "    Y_shuffled = Y[indices]\n",
        "\n",
        "    # Split into k approximately equal-sized folds\n",
        "    fold_size = len(X) // k\n",
        "    folds_X = []\n",
        "    folds_Y = []\n",
        "\n",
        "    for i in range(k):\n",
        "        start = i * fold_size\n",
        "        # Handling last fold\n",
        "        end = min((i + 1) * fold_size, len(X))\n",
        "\n",
        "        folds_X.append(X_shuffled[start:end])\n",
        "        folds_Y.append(Y_shuffled[start:end])\n",
        "\n",
        "    return folds_X, folds_Y\n",
        "\n",
        "\n",
        "def kFoldCrossValidation(X, Y, learningRate, epochs, k=5, classThresh=0.5):\n",
        "    # Create k folds\n",
        "    folds_X, folds_Y = createKFolds(X, Y, k)\n",
        "\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for i in range(k):\n",
        "        # Prepare training and validation data for the ith fold\n",
        "        X_train = np.vstack([folds_X[j] for j in range(k) if j != i])\n",
        "        Y_train = np.hstack([folds_Y[j] for j in range(k) if j != i])\n",
        "\n",
        "        X_val = folds_X[i]\n",
        "        Y_val = folds_Y[i]\n",
        "\n",
        "        X_train = fit_min_max_scaling(X_train)\n",
        "        X_val = fit_min_max_scaling(X_val)\n",
        "\n",
        "        # Initialize the logistic regression model\n",
        "        model = LogisticRegression(learningRate, epochs, classThresh)\n",
        "\n",
        "        # Train the model using Batch Gradient Descent\n",
        "        model.gradientDescent(X_train, Y_train)\n",
        "\n",
        "        # Get predictions for the validation set\n",
        "        Y_pred = np.array(model.classify(X_val))\n",
        "\n",
        "        # Calculate validation loss and accuracy\n",
        "        epsilon = 1e-10\n",
        "        val_loss = -(1/len(Y_val)) * np.sum(Y_val * np.log(Y_pred + epsilon) + (1 - Y_val) * np.log(1 - Y_pred + epsilon))\n",
        "        val_accuracy = accuracy(Y_pred, Y_val)\n",
        "\n",
        "        precisions.append(precision_score(Y_val, Y_pred, zero_division=0))\n",
        "        recalls.append(recall_score(Y_val, Y_pred, zero_division=0))\n",
        "        f1_scores.append(f1_score(Y_val, Y_pred, zero_division=0))\n",
        "\n",
        "        # Store the performance metrics for this fold\n",
        "        losses.append(val_loss)\n",
        "        accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Fold {i + 1}: Loss = {val_loss:.4f}, Accuracy = {val_accuracy:.4f}\")\n",
        "        print(f\"Fold {i + 1}: Precision = {precisions[-1]:.4f}, Recall = {recalls[-1]:.4f}, F1 Score = {f1_scores[-1]:.4f}\")\n",
        "        print()\n",
        "\n",
        "    # Compute and print average loss and accuracy over all folds\n",
        "\n",
        "    print(\"--------------%%%%%----------------\")\n",
        "    print(f\"Mean Loss: {np.mean(losses):.4f}\")\n",
        "    print(f\"Std Loss: {np.std(losses):.4f}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
        "    print(f\"Std Accuracy: {np.std(accuracies):.4f}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
        "    print(f\"Std Precision: {np.std(precisions):.4f}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
        "    print(f\"Std Recall: {np.std(recalls):.4f}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "    print(f\"Std F1 Score: {np.std(f1_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIcaNALHI8zl",
        "outputId": "9dcb2a23-1593-4f4e-f31b-b19211517706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Loss = 3.7787, Accuracy = 0.8359\n",
            "Fold 1: Precision = 1.0000, Recall = 0.0211, F1 Score = 0.0414\n",
            "\n",
            "Fold 2: Loss = 3.1535, Accuracy = 0.8630\n",
            "Fold 2: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
            "\n",
            "Fold 3: Loss = 3.5884, Accuracy = 0.8442\n",
            "Fold 3: Precision = 0.4583, Recall = 0.0846, F1 Score = 0.1429\n",
            "\n",
            "Fold 4: Loss = 3.5069, Accuracy = 0.8477\n",
            "Fold 4: Precision = 0.0000, Recall = 0.0000, F1 Score = 0.0000\n",
            "\n",
            "Fold 5: Loss = 3.4253, Accuracy = 0.8512\n",
            "Fold 5: Precision = 0.5556, Recall = 0.0394, F1 Score = 0.0735\n",
            "\n",
            "--------------%%%%%----------------\n",
            "Mean Loss: 3.4906\n",
            "Std Loss: 0.2053\n",
            "\n",
            "Mean Accuracy: 0.8484\n",
            "Std Accuracy: 0.0089\n",
            "\n",
            "Mean Precision: 0.4028\n",
            "Std Precision: 0.3762\n",
            "\n",
            "Mean Recall: 0.0290\n",
            "Std Recall: 0.0314\n",
            "\n",
            "Mean F1 Score: 0.0516\n",
            "Std F1 Score: 0.0534\n"
          ]
        }
      ],
      "source": [
        "learningRate = 0.01\n",
        "epochs = 500\n",
        "ct = 0.5\n",
        "\n",
        "kFoldCrossValidation(X_train, Y_train, learningRate, epochs, k=5, classThresh=ct)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
